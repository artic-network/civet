```python, name="import_dependencies", echo=False
import matplotlib.pyplot as pyplot
import pandas as pd 
import os
import matplotlib.font_manager as font_manager
import matplotlib as mpl
import tabulate
import csv
import numpy as np
import scipy as sp
import warnings
warnings.filterwarnings("ignore")
from dateutil.relativedelta import relativedelta, FR
import datetime as dt

import mapping as mapping

from reportfunk.funks import time_functions as time_func
from reportfunk.funks import prep_data_functions as prep_data
from reportfunk.funks import tree_functions as tree_viz
from reportfunk.funks import parsing_functions as dp
from reportfunk.funks import table_functions as table_func
import civetfunks as cfunk


```

```python, name="insert_arguments", echo=False, results='raw'
##INSERT_ARGUMENTS
```
```python, name="prepare_arguments", echo=False, results='raw'

name_stem, tree_fields, colour_by, label_fields, date_fields, table_fields = cfunk.prepping_civet_arguments(name_stem, tree_fields, colour_by, label_fields, date_fields, table_fields)

if "adm2" in background_metadata_header or "adm2" in query_metadata_header:
    adm2_to_adm1 = prep_data.prepping_adm2_adm1_data(background_metadata, background_metadata_header)
else:
    adm2_to_adm1 = None

mapping_json_files = [uk_map, channels_map, ni_map]

font_props = font_manager.FontProperties(family=["sans-serif"])
a = matplotlib.font_manager.FontManager()
a.findfont(font_props, fallback_to_default=True)
pyplot.rcParams.update({'figure.max_open_warning': 0})
mpl.rcParams['font.weight']=50
mpl.rcParams['axes.labelweight']=50

tree_inputs = [tree_fields, label_fields, colour_by, node_summary]
map_inputs = [map_sequences, colour_map_by, map_info]
```

```python, name="header",echo=False, results='raw'
print(f"![]({sequencing_centre_file})")
```

##INSERT_TITLE

##OUTBREAKID

##DATE

##AUTHORS

```python, name="print description", echo=False, results='raw'
##DESCRIPTION

```

```python, name="parse metadata", echo=False, results='raw'
database_column = "sequence_name" #this has to be here for now because of the ID versus three part name issue. At some point it'll need to be made flexible.
full_tax_dict, query_dict, tree_to_tip, tree_to_all_tip, inserted_node_dict, adm2_present_in_metadata, full_query_count, old_data = dp.parse_all_metadata(treedir, collapse_summary, filtered_background_metadata, background_metadata, query, input_column, database_column, database_sample_date_column, display_name, sample_date_column, label_fields, tree_fields, table_fields, node_summary, context_table_summary, date_fields=date_fields, UK_adm2_adm1_dict=adm2_to_adm1)
#anonymise sequences based on safe status
full_tax_dict = cfunk.anonymise_sequences(full_tax_dict, query_dict, safety_level, from_metadata)

time_outputs = time_func.summarise_dates(query_dict)
if type(time_outputs) != bool:
    overall_dates, max_overall_date, min_overall_date,  max_string, min_string = time_outputs
    dates_present = True
else:
    dates_present = False
```

```python, name="QC fails", echo=False, results="raw"
if qc_fail != "": 
    fail_dict = dp.investigate_QC_fails(qc_fail, input_column)
    if len(fail_dict) > 0:
        print("The following sequences have failed QC:\n")
        for seq, reason in fail_dict.items():
            pretty_name = seq.replace("'","")
            pretty_reason = reason.replace("'","")
            print(" - " + pretty_name, pretty_reason)
print("\n")
missing_list = dp.investigate_missing_sequences(missing_sequences)
if len(missing_list) > 0:
    if fasta != "":
        print("The following queries were not found in the background database and were not provided in the fasta file.")
    else:
        print("The following queries were not found in the background database and no fasta was provided.")
    
    for seq in missing_list:
        print(" - " + seq)

    print("\n")
    print("If it is a surprise that the queries are not in the background database, please check that there are no typos in the IDs you have provided, as they must match exactly to the background database to be included. The --data-column and --input-column arguments may need to be adjusted to ensure the correct columns are being matched.")
    print("The query may also not have enough genome coverage to be included in the background dataset - if this is the case, they must be provided using a fasta file in order to be included in civet.")
    


```

```python, name="early descriptions", echo=False, results='tex'
number_seqs = len(query_dict)
not_found_in_climb = full_query_count - number_seqs

cog_number = 0
not_in_cog_number = 0
for tax in query_dict.values():
    if tax.in_db:
        cog_number += 1
    else:
        not_in_cog_number += 1

if not omit_trees:
    prep_data.analyse_tree_inputs(tree_inputs)
if map_sequences:
    prep_data.analyse_map_inputs(map_inputs)

print("\n")

print(str(full_query_count) + " queries (" + str(cog_number) + " matched to COG-UK database)")
print(str(not_in_cog_number) + " sequences input")
if not_found_in_climb:
    print(str(not_found_in_climb) + " not found in background data")

if dates_present:
    print("Time fields provided: " + ",".join(date_fields))
    print("Earliest date: " + min_string)
    print("Latest date: " + max_string)
else:
    print("No time information provided")
```


```python, name="first_table", echo=False, results="tex"
table_count = 0
output = table_func.make_custom_table(query_dict, full_tax_dict, table_fields, remove_snp_table)
if cog_number != 0 and not_in_cog_number != 0:
    table_count += 1
    df_cog, df_seqs = output
    print(f"**Table {table_count}** | Queries found in COG-UK database.\n")
    print(df_cog.to_markdown())
    print("\n")
    table_count += 1
    print(f"**Table {table_count}** | Queries matched to closest COG-UK sequence using input sequences\n")
    print(df_seqs.to_markdown())
elif cog_number == 0 and not_in_cog_number != 0:
    table_count += 1
    df_seqs = output
    print(f"**Table {table_count}** | Queries matched to closest COG-UK sequence using input sequences\n")
    print(df_seqs.to_markdown())
elif not_in_cog_number == 0 and cog_number != 0:
    table_count += 1
    df_cog = output
    print(f"**Table {table_count}**| Queries found in COG-UK database.\n")
    print(df_cog.to_markdown())
```

```python, name="make_trees", echo=False, include=False, figure=False
too_tall_trees, overall_tree_number, colour_dict_dict, overall_df_dict, tree_order, too_large_tree_dict, tallest_height,tree_to_num_tips = tree_viz.make_all_of_the_trees(treedir, tree_name_stem, full_tax_dict, query_dict, tree_fields, label_fields, colour_by, tree_to_all_tip, tree_to_tip, inserted_node_dict, svg_figdir, safety_level=safety_level)

```
```python, name="make_legend", echo=False, include=False, results='tex'
for trait, colour_dict in colour_dict_dict.items():
    tree_viz.make_legend(colour_dict_dict)
    number_of_options = len(colour_dict)
    if number_of_options > 15:
        print("WARNING: There are more than 15 options to colour by for " + trait + ", which will make it difficult to see the differences between colours. Consider adding the trait to the taxon labels on the tree by using the flag _--label-fields_ when calling CIVET.")
```
```python, name="time_plot", echo=False, results='raw', include=False
if dates_present:
    count = 0
    tree_to_time_series = {}
    for tree in tree_order:
        lookup = f"{tree_name_stem}_{tree}"
        tips = tree_to_tip[lookup]
        if len(tips) > 1:
            count += 1
            time_func.plot_time_series(tips, query_dict, max_overall_date, min_overall_date, date_fields, label_fields, lookup, svg_figdir, safety_level = safety_level)
            tree_to_time_series[lookup] = count
```

```python, name="show_trees", echo=False, results='raw'
if not omit_trees:
    for i in range(1,overall_tree_number+1):
        tree_name = "Tree " + str(i)
        lookup = f"{tree_name_stem}_{i}"
        print(f"> **Tree {i}** | ")
        if len(tree_to_tip[lookup]) == 1:
            print(f"1 sequence of interest")
        else:
            print(f"{len(tree_to_tip[lookup])} sequences of interest")
        print("   ")
        
        if lookup not in too_tall_trees:
            print(f"![]({figdir}/{name_stem}_make_trees_{i}.png)")

            print(f'<img src="{figdir}/{name_stem}_make_legend_1.png" alt="drawing" style="width:100%;"/>')
            print("\n")

            if dates_present and lookup in tree_to_time_series.keys():
                print("![](" + figdir + "/" + name_stem + "_time_plot_" + str(tree_to_time_series[lookup]) + ".png)")

            if not no_snipit:
                print(f"![]({figdir}/genome_graph_{lookup}.png)")

        else:
            print(tree_name + " was too large to be rendered. Please see summary table below. If visualisation is required, please use intermediate tree files and use software such as Figtree.")

if too_tall_trees != []:
    print("### Large tree summaries\n")
    print("NB: data in subtrees within this tree is not included in the summary here.")
    df_large_trees = pd.DataFrame(too_large_tree_dict)
    df_large_trees.set_index("Tree name", inplace=True)
    print(df_large_trees.to_markdown())

```

```python, name="global_snipit", echo=False, results='raw'
if global_snipit:
    print("""\n\n### Global snipit\n\nsnipit figure highlighting the SNP diversity among all focal input sequences relative to the reference""")
    print(f"![]({figdir}/genome_graph_global_focal.png)")
```

```python, name="tree_background", echo=False, include=False,  results='raw'
if include_bars:
    print("""### Tree background\n\nThe following plots describe the data in the collapsed nodes in more detail.\nIf more than one """ + node_summary + """ was present, the bar chart describes the number of sequences present in each """ + node_summary + """. \nWhere there were 10 options or more, the largest 10 have been taken.""")
    bar_count = tree_viz.describe_collapsed_nodes(full_tax_dict, tree_name_stem, treedir, node_summary)
    if node_summary == "country":
        print("If a UK sequence is present in the collapsed node, it is always shown in the plot.")
```
```python, name="show_background",echo=False,include=False,results='raw'
if include_bars:
    if bar_count == 0:
        print(f"There were no nodes that needed to be shown, as there were no collapsed nodes with more than two of {node_summary} in.")
    for i in range(bar_count):
        print(f"![]({figdir}/{name_stem}_tree_background_{i+1}.png)")

```

```python, name="context_table", echo=False, results='raw', include=False
if context_table_summary:
    print("### CONTEXT")
    table_count += 1
    print(f"**Table {table_count}** | Context for queries using {context_table_summary}.\n")
    context_table, closest_values, no_values = table_func.context_table(query_dict, full_tax_dict, context_table_summary)
    print(context_table.to_markdown())
    if len(closest_values) > 0:
        print("\n")
        print(f"NB the following sequences were not found in the database, and so the {context_table_summary} was taken from the closet sequence: ")
        for query, value in closest_values.items():
            print(f"- {query}: {value}")
    if len(no_values) > 0:
        print("\n")
        print(f"The following sequences were not found in the database, and the closest sequence had no data for {context_table_summary}")
        for i in no_values:
            print(f" - {i} \n")
    print("\n")
```

```python, name="map_sequences", echo=False, results='raw', include=False
if map_sequences:
    stop_map = False
    if "adm2" in map_info:
        output = mapping.map_adm2(query_dict, clean_locs_file, mapping_json_files, svg_figdir, query, background_metadata, query_metadata_header, background_metadata_header,input_column, data_column, map_info, old_data)
        if output:
            adm2_in_map, adm2_percentages, adm2_to_label = output
        else:
            stop_map = True
    else:
        output = mapping.map_sequences_using_coordinates(query, background_metadata, query_metadata_header, background_metadata_header, input_column, data_column, mapping_json_files, urban_centres, pc_file, colour_map_by, map_info, input_crs, svg_figdir)
        if output:
            adm2_in_map, adm2_percentages = output
            adm2_to_label = {}
        else:
            stop_map = True
        
    if not stop_map:
        print("## Plotting sequences")

        print("There are sequences from " + str(len(adm2_in_map)) + " admin2 regions")

        print("This is divided into:")
        for adm2,percentage in adm2_percentages.items():
            if adm2 in adm2_to_label:
                print(f'{percentage}% ({adm2_in_map[adm2]}) in {adm2}, otherwise known as {adm2_to_label[adm2]}')
            else:
                print(f'{percentage}% ({adm2_in_map[adm2]}) in {adm2}')

        if colour_map_by:
            print("This is shown in the map below, and is coloured by " + colour_map_by + " and urban centres are shown in the darker grey")
        else:
            if map_info != "adm2":
                print("This is shown in the map below, with urban centres shown in the darker grey")

    else:
        print("Insufficient geographical information to plot sequences")
```
```python, name="show_map", echo=False, results='raw'
if map_sequences and not stop_map:
    print("![](" + figdir + "/" + name_stem + "_map_sequences_1.png)")
```

```python, name='Regional-scale', echo=False, results='raw'
if local_lineages:
    print("## Regional-scale background UK lineage mapping")
    mapping.local_lineages_section(lineage_maps, lineage_tables, date_restriction, date_range_start, date_range_end, date_window)
```

```python, name="print conclusions", echo=False, results='raw'
##CONCLUSIONS

```
```python, name='write_summary_file', echo=False, results='raw'
cfunk.make_full_civet_table(query_dict, full_tax_dict, tree_fields, label_fields, input_column, outdir, table_fields)
```

##APPENDIX

### Software versions

This report was made using:

```python, name='software versions', echo=False, results='raw'

import platform


print("Python " + platform.python_version())

print("Matplotlib version " + matplotlib.__version__)
print("Pandas version " + pd.__version__)
print("Tabulate version " + tabulate.__version__)
print("CSV version " + csv.__version__)
print("Numpy version " + np.__version__)
print("Scipy version " + sp.__version__)
print("No version number for Baltic")

if data_date != "":
    print("COG data from " + data_date + " was used as background data.")
else:
    yesterday = dt.date.today() - dt.timedelta(1)
    print("COG data from " + str(yesterday))


print("CIVET version is 2.0")
```

## Acknowledgements

This report was generated by CIVET, made primarily by Aine O'Toole and Verity Hill, using code from Rambaut Lab members.

The background data from the UK was generated by the COG consortium (https://www.cogconsortium.uk/), a national, multi-centre consortium for the sequencing and analysis of SARS-CoV-2 genomes for Public Health.

We also use some background data from GISAID (https://www.gisaid.org/) in the phylogenies. We thank everyone involved in the global sequencing effort for making their data available. 

Tree data was visualised using baltic (https://github.com/evogytis/baltic)

Mapping data was downloaded from the Global Administrative Database (https://gadm.org/) and Natural Earth (https://www.naturalearthdata.com/)

```python, name="footer", echo=False, results='raw'
print("![](" + figdir + "/footer.png)")
```
